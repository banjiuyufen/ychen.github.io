<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Yi Chen</title>
</head>
<body style="width: 1000px; margin: 0 auto;">
<div id="fwtitle">
<div id="toptitle">
<h1>Yi Chen</h1>
</div>
</div>
<div id="layout-content">
<table class="imgtable"><tr><td>
<img src="ychen.jpg" alt="photo_me" width="190px" height="200px" />&nbsp;</td>
<td align="left"><p>PhD Student<br />
State Key Laboratory of Multimodal Artificial Intelligence Systems (MAIS) <br/> Institution of Automation, Chinese Academy of Sciences </p>
<p>Beijing 100190, China.<br />  
Email: yi.chen@nlpr.ia.ac.cn</a>

</p>
</td></tr></table>
<h2>About me</h2>
<p>I am currently a PhD student in the State Key Laboratory of Multimodal Artificial Intelligence Systems at Institution of Automation, Chinese Academy of Sciences, where I am advised by Prof. Cheng-Lin Liu.
I received the B.E degree from the School of Space Science and Technology at Xidian University in 2017; I recevied my Master degree in electronic information from the State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, where I was advised by Prof. Cheng-Lin Liu.
</p>
My research interests include the following pointsï¼š
<!-- My research interests include topics in machine learning and optimization. My goal is to make machine learning systems more robust. -->
</p>
<ul>
<li>Chinese text line recognition and generation;
</li>
<li>Large language model and multimodal large model;
</li>
<li>The practice and application of artificial intelligence methods in science (Ai for Science), especially in the fields of biology, chemistry, and materials.
</li>
</ul>

<!-- <b>I'm on the 2023-2024 academic job market.</b> -->



<!-- <h2>News</h2>

<ul>
	   <li>
	   	[11/9/2018] We won the <b>1st place</b> in both Robust Model Track and Targeted Attack Track, as well as <b>the 3rd place</b> in Untargeted Attack Track in <a href="https://www.crowdai.org/challenges/nips-2018-adversarial-vision-challenge-robust-model-track">NeurIPS 2018 : Adversarial Vision Challenge</a> [<a href="https://medium.com/bethgelab/results-of-the-nips-adversarial-vision-challenge-2018-e1e21b690149">News Link</a>]. Congratulations to our team! Please check our new method <b>TRADES</b> [<a href="https://arxiv.org/abs/1901.08573">paper</a>] [<a href="https://github.com/yaodongyu/TRADES">code</a>].
       </li>
</ul> -->

<h2>Preprints [<a href="https://scholar.google.com/citations?user=XoiT9wMAAAAJ&hl=zh-CN">Google Scholar</a>] </h2> 
       (*: equal contribution)
<!-- <h3>Preprints</h3>
<ul>
<li><p><i>Saving Gradient and Negative Curvature Computations: Finding Local Minima More Efficiently</i>.<br /> 
<b>Yaodong Yu</b>*, Difan Zou* and Quanquan Gu (*: equal contribution). arXiv:1712.03950, 2017. [<a href="https://arxiv.org/abs/1712.03950">arXiv</a>]<br /></p>
</li>
</ul> -->

<!-- <h3>Conference Proceedings</h3> -->
<ul>
<li><p><i>Recoverable compression: A multimodal vision token recovery mechanism guided by text information</i>.<br />
<b>Yi Chen</b>, Jian Xu, Xu-Yao Zhang, Wen-Zhuo Liu, Yang-Yang Liu, Cheng-Lin Liu. <br />  
The 39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025), 2025. [<a href="Y Chen, J Xu, XY Zhang, WZ Liu, YY Liu, CL Liu">arxiv</a>] [<a href="https://github.com/banjiuyufen/Recoverable-Compression">code</a>]<br /></p>
</li>
</ul>
<ul>
<li><p><i>Balancing performance and efficiency: A multimodal large language model pruning method based image text interaction</i>.<br />
Gao-Tong Yu*, <b>Yi Chen*</b>, Jian Xu. <br />  
[<a href="https://arxiv.org/abs/2409.01162">arXiv</a>]<br /></p>
</li>
</ul>
<ul>
<li><p><i>Decoupling Layout from Glyph in Online Chinese Handwriting Generation</i>.<br />
Min-Si Ren, Yan-Ming Zhang, <b>Yi Chen</b>. <br />  
[<a href="https://arxiv.org/abs/2410.02309">link</a>]<br /></p>
</li>
</ul>
<ul>
<li><p><i>Recognition of Online Handwritten Chinese Texts in Any Writing Direction via Stroke Classification Based Over-Segmentation</i>.<br />
<b>Y Chen</b>, Heng Zhang, Min-Si Ren, Cheng-Lin Liu. <br />  
The 27th International Conference on Pattern Recognition (ICPR2024), 2024. [<a href="https://link.springer.com/chapter/10.1007/978-3-031-78183-4_24">link</a>] <br /></p>
</li>
</ul>
<ul>
<li><p><i>Context-Aware Confidence Estimation for Rejection in Handwritten Chinese Text Recognition</i>.<br />
Yang-Yang Liu, <b>Y Chen</b>, Fei Yin, Cheng-Lin Liu. <br />  
The 18th International Conference on Document Analysis and Recognition (ICDAR2024), 2024. [<a href="https://link.springer.com/chapter/10.1007/978-3-031-70533-5_9">link</a>] <br /></p>
</li>
</ul>
<ul>
<li><p><i>Improved Learning for Online Handwritten Chinese Text Recognition with Convolutional Prototype Network</i>.<br />
<b>Y Chen</b>, Heng Zhang, Cheng-Lin Liu. <br />  
The 17th International Conference on Document Analysis and Recognition (ICDAR2023), 2023. [<a href="https://link.springer.com/chapter/10.1007/978-3-031-41685-9_3">link</a>] <br /></p>
</li>
</ul>


</div>
</body>
</html>
